{"primaryContentSections":[{"kind":"content","content":[{"anchor":"AppleSampler-and-MIDISampler","level":2,"type":"heading","text":"AppleSampler and MIDISampler"},{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"NOTE:"}]},{"type":"text","text":" In earlier versions of AudioKit, "},{"type":"strong","inlineContent":[{"type":"text","text":"AppleSampler"}]},{"type":"text","text":" was called "},{"type":"strong","inlineContent":[{"type":"text","text":"Sampler"}]},{"type":"text","text":"."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Apple’s "},{"type":"emphasis","inlineContent":[{"type":"text","text":"AUSampler"}]},{"type":"text","text":" Audio Unit, despite a few unfortunate flaws, is exceptionally powerful, and has served as the basis for countless sample-based iOS music apps. It has five huge advantages over the other two sampler modules:"}]},{"type":"orderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"emphasis","inlineContent":[{"type":"text","text":"Streaming:"}]},{"type":"text","text":" AUSampler plays sample data directly from files; it is not necessary to pre-load samples into memory."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"AUSampler is "},{"type":"emphasis","inlineContent":[{"type":"text","text":"polytimbral:"}]},{"type":"text","text":" Sounds can be defined using multiple "},{"type":"emphasis","inlineContent":[{"type":"text","text":"layers"}]},{"type":"text","text":", so each note can involve multiple samples played back in different combinations. Each layer can optionally include a low-pass filter with resonance, one or more envelope generators, and one or more LFOs for modulation."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"It features a "},{"type":"emphasis","inlineContent":[{"type":"text","text":"modular architecture"}]},{"type":"text","text":", where the number and interconnection of sample oscillators and LFOs in each layer can be defined dynamically, expressed in a “metadata” file."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"It can "},{"type":"emphasis","inlineContent":[{"type":"text","text":"import multiple metadata file formats"}]},{"type":"text","text":", which describe how whole sets of samples are mapped across the MIDI keyboard and affected by MIDI key velocity, together with layer structures, modulation, etc."}]}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The Mac version can be loaded as a plug-in into a DAW such as "},{"type":"emphasis","inlineContent":[{"type":"text","text":"Logic Pro X"}]},{"type":"text","text":", and includes a GUI for defining layer structures, modulation and real-time MIDI control, and the mapping of MIDI note\/velocity to samples."}]}]}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Unfortunately, "},{"type":"emphasis","inlineContent":[{"type":"text","text":"AUSampler"}]},{"type":"text","text":" has some fatal flaws, and indeed appears to be an unfinished project. Using it as a plug-in on the Mac, to develop sample-based instruments (sample sets + metadata) tends to be an exercise in frustration. It can crash the DAW. Using AUSamplers plug-in in a DAW gives a GUI which is supposed to be able to read "},{"type":"reference","isActive":true,"identifier":"https:\/\/www.lifewire.com\/sfz-file-2622282"},{"type":"text","text":", DLS and EXS24 metadata files, but in practice rarely does so perfectly. Its native "},{"type":"codeVoice","code":".aupreset"},{"type":"text","text":" metadata format, which is a "},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/library\/content\/documentation\/Cocoa\/Conceptual\/PropertyLists\/Introduction\/Introduction.html"},{"type":"text","text":", is undocumented and confusing. The  "},{"type":"codeVoice","code":".aupreset"},{"type":"text","text":" can be edited within Xcode Property List editor. After converting a EXS24 or before deploying to iOS usually the paths need to be manually fixed. See "},{"type":"reference","isActive":true,"identifier":"https:\/\/developer.apple.com\/library\/content\/technotes\/tn2283\/_index.html"},{"type":"text","text":". The  "},{"type":"codeVoice","code":".aupreset"},{"type":"text","text":" can also be programmatically edited using "},{"type":"strong","inlineContent":[{"type":"text","text":"PresetManager"}]},{"type":"text","text":" and "},{"type":"strong","inlineContent":[{"type":"text","text":"PresetBuilder"}]},{"type":"text","text":". "},{"type":"reference","isActive":true,"identifier":"https:\/\/stackoverflow.com\/questions\/47359088\/playing-multi-sampled-instruments-using-audiokit-controlling-adsr-envelope\/47370008#47370008"},{"type":"text","text":"."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"The AudioKit class "},{"type":"strong","inlineContent":[{"type":"text","text":"AppleSampler"}]},{"type":"text","text":" basically just wraps an instance of "},{"type":"emphasis","inlineContent":[{"type":"text","text":"AUsampler"}]},{"type":"text","text":" and makes its Objective-C based API accessible from Swift. Most music apps use the higher-level "},{"type":"strong","inlineContent":[{"type":"text","text":"MIDISampler"}]},{"type":"text","text":" class, whose "},{"type":"codeVoice","code":"enableMIDI()"},{"type":"text","text":" function connects it directly to the stream of incoming MIDI data."}]},{"anchor":"Apple-Sampler-Notes","level":2,"type":"heading","text":"Apple Sampler Notes"},{"anchor":"Making-AppleSampler-not-get-corrupted-by-an-audio-route-change","level":3,"type":"heading","text":"Making AppleSampler not get corrupted by an audio route change"},{"type":"paragraph","inlineContent":[{"type":"text","text":"When the audio session route changes (the iOS device is plugged into an external sound interface, headphones are connected, you start capturing a video on a mac using Quicktime…) Samplers start producing distorted audio."}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Registering for audio route changes is simple and doesn’t require anything from the basic app flow like the delegate or view controllers. Just do:"}]},{"type":"codeListing","syntax":null,"code":["NotificationCenter.default.addObserver(self, selector: #selector(routeChanged), name: .AVAudioSessionRouteChange, object: AVAudioSession.sharedInstance())"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Define the event handler:"}]},{"type":"codeListing","syntax":null,"code":["@objc func routeChanged(_ notification: Notification) {","    Log(\"Audio route changed\")","    ","    AudioKit.stop() \/\/ Note 1","","    do {","        try sampler.loadEXS24(yourSounds) \/\/ Note 2","    } catch  {","        Log(\"could not load samples\")","    }","","    AudioKit.start()","}"]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Note 1: Sometimes stopping and starting AudioKit is not necessary. I suspect that this has something to do with sampling rates and bit rates, but I didn’t investigate further, because I needed to support the stricter case anyway"}]},{"type":"paragraph","inlineContent":[{"type":"text","text":"Note 2: Samplers need to reload. AudioKit could implement route tracking in the main singleton, register all samplers and do this automatically to work properly out of the box."}]}]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"sections":[],"variants":[{"paths":["\/documentation\/audiokit\/samplers"],"traits":[{"interfaceLanguage":"swift"}]}],"identifier":{"url":"doc:\/\/AudioKit\/documentation\/AudioKit\/Samplers","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"The term “sampler” is a bit misleading. Originally, it referred to a hardware device capable of recording (“sampling”) sound and then re-playing it from a keyboard. In practice, the playback aspect proved to be far more popular then the recording aspect, and today the two functions are nearly always completely separated. What we call a “sampler” today is simply a system for replaying previously-prepared sounds (“samples”)."}],"kind":"article","metadata":{"roleHeading":"Article","title":"Samplers","role":"article","modules":[{"name":"AudioKit"}]},"hierarchy":{"paths":[["doc:\/\/AudioKit\/documentation\/AudioKit"]]},"references":{"https://developer.apple.com/library/content/technotes/tn2283/_index.html":{"title":"Apple Technical Note TN2283","titleInlineContent":[{"type":"text","text":"Apple Technical Note TN2283"}],"type":"link","identifier":"https:\/\/developer.apple.com\/library\/content\/technotes\/tn2283\/_index.html","url":"https:\/\/developer.apple.com\/library\/content\/technotes\/tn2283\/_index.html"},"doc://AudioKit/documentation/AudioKit":{"role":"collection","title":"AudioKit","abstract":[{"type":"text","text":"Swift audio synthesis, processing, & analysis platform for iOS, macOS and tvOS"}],"identifier":"doc:\/\/AudioKit\/documentation\/AudioKit","kind":"symbol","type":"topic","url":"\/documentation\/audiokit"},"https://www.lifewire.com/sfz-file-2622282":{"title":"SoundFont","titleInlineContent":[{"type":"text","text":"SoundFont"}],"type":"link","identifier":"https:\/\/www.lifewire.com\/sfz-file-2622282","url":"https:\/\/www.lifewire.com\/sfz-file-2622282"},"https://stackoverflow.com/questions/47359088/playing-multi-sampled-instruments-using-audiokit-controlling-adsr-envelope/47370008#47370008":{"title":"External example in StackOverflow","titleInlineContent":[{"type":"text","text":"External example in StackOverflow"}],"type":"link","identifier":"https:\/\/stackoverflow.com\/questions\/47359088\/playing-multi-sampled-instruments-using-audiokit-controlling-adsr-envelope\/47370008#47370008","url":"https:\/\/stackoverflow.com\/questions\/47359088\/playing-multi-sampled-instruments-using-audiokit-controlling-adsr-envelope\/47370008#47370008"},"https://developer.apple.com/library/content/documentation/Cocoa/Conceptual/PropertyLists/Introduction/Introduction.html":{"title":"Property List","titleInlineContent":[{"type":"text","text":"Property List"}],"type":"link","identifier":"https:\/\/developer.apple.com\/library\/content\/documentation\/Cocoa\/Conceptual\/PropertyLists\/Introduction\/Introduction.html","url":"https:\/\/developer.apple.com\/library\/content\/documentation\/Cocoa\/Conceptual\/PropertyLists\/Introduction\/Introduction.html"}}}