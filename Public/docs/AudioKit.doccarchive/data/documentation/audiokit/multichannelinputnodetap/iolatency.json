{"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"ioLatency"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"AVAudioFrameCount","preciseIdentifier":"c:@T@AVAudioFrameCount"}],"languages":["swift"],"platforms":["macOS"]}]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"sections":[],"variants":[{"paths":["\/documentation\/audiokit\/multichannelinputnodetap\/iolatency"],"traits":[{"interfaceLanguage":"swift"}]}],"identifier":{"url":"doc:\/\/AudioKit\/documentation\/AudioKit\/MultiChannelInputNodeTap\/ioLatency","interfaceLanguage":"swift"},"abstract":[{"type":"text","text":"Optional latency offset that you should set after determining the correct latency"},{"type":"text","text":" "},{"type":"text","text":"for your hardware. This amount of samples will be skipped by the first write."},{"type":"text","text":" "},{"type":"text","text":"While AVAudioInputNode provides a "},{"type":"codeVoice","code":"presentationLatency"},{"type":"text","text":" value, I don’t see the"},{"type":"text","text":" "},{"type":"text","text":"value returned being accurate on macOS. For lack of the CoreAudio latency"},{"type":"text","text":" "},{"type":"text","text":"calculations, you could use that value. Default value is zero."}],"kind":"symbol","metadata":{"fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"ioLatency"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"AVAudioFrameCount","preciseIdentifier":"c:@T@AVAudioFrameCount"}],"title":"ioLatency","roleHeading":"Instance Property","role":"symbol","symbolKind":"property","externalID":"s:8AudioKit24MultiChannelInputNodeTapC9ioLatencys6UInt32Vvp","modules":[{"name":"AudioKit"}]},"hierarchy":{"paths":[["doc:\/\/AudioKit\/documentation\/AudioKit","doc:\/\/AudioKit\/documentation\/AudioKit\/MultiChannelInputNodeTap"]]},"references":{"doc://AudioKit/documentation/AudioKit/MultiChannelInputNodeTap":{"role":"symbol","title":"MultiChannelInputNodeTap","fragments":[{"kind":"keyword","text":"class"},{"kind":"text","text":" "},{"kind":"identifier","text":"MultiChannelInputNodeTap"}],"abstract":[{"type":"text","text":"MultiChannelInputNodeTap is a tap intended to process multiple channels of audio"},{"type":"text","text":" "},{"type":"text","text":"from AVAudioInputNode, or the AVAudioEngine’s inputNode. In the case of the engine"},{"type":"text","text":" "},{"type":"text","text":"the input node will have a set of channels that correspond to the hardware being"},{"type":"text","text":" "},{"type":"text","text":"used. This class will read from those channels and write discrete mono files for"},{"type":"text","text":" "},{"type":"text","text":"each similar to how common DAWs record multiple channels from multiple inputs."}],"identifier":"doc:\/\/AudioKit\/documentation\/AudioKit\/MultiChannelInputNodeTap","kind":"symbol","type":"topic","navigatorTitle":[{"kind":"identifier","text":"MultiChannelInputNodeTap"}],"url":"\/documentation\/audiokit\/multichannelinputnodetap"},"doc://AudioKit/documentation/AudioKit":{"role":"collection","title":"AudioKit","abstract":[{"type":"text","text":"Swift audio synthesis, processing, & analysis platform for iOS, macOS and tvOS"}],"identifier":"doc:\/\/AudioKit\/documentation\/AudioKit","kind":"symbol","type":"topic","url":"\/documentation\/audiokit"},"doc://AudioKit/documentation/AudioKit/MultiChannelInputNodeTap/ioLatency":{"role":"symbol","title":"ioLatency","fragments":[{"kind":"keyword","text":"var"},{"kind":"text","text":" "},{"kind":"identifier","text":"ioLatency"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"AVAudioFrameCount","preciseIdentifier":"c:@T@AVAudioFrameCount"}],"abstract":[{"type":"text","text":"Optional latency offset that you should set after determining the correct latency"},{"type":"text","text":" "},{"type":"text","text":"for your hardware. This amount of samples will be skipped by the first write."},{"type":"text","text":" "},{"type":"text","text":"While AVAudioInputNode provides a "},{"type":"codeVoice","code":"presentationLatency"},{"type":"text","text":" value, I don’t see the"},{"type":"text","text":" "},{"type":"text","text":"value returned being accurate on macOS. For lack of the CoreAudio latency"},{"type":"text","text":" "},{"type":"text","text":"calculations, you could use that value. Default value is zero."}],"identifier":"doc:\/\/AudioKit\/documentation\/AudioKit\/MultiChannelInputNodeTap\/ioLatency","kind":"symbol","type":"topic","url":"\/documentation\/audiokit\/multichannelinputnodetap\/iolatency"}}}